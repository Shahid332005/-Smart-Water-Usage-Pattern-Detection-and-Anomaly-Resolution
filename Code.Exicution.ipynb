import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.cluster import KMeans
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input
from tensorflow.keras.callbacks import EarlyStopping

# Set random seeds for reproducibility
np.random.seed(42)
import tensorflow as tf
tf.random.set_seed(42)

# ==========================================
# 1. SYNTHETIC DATA GENERATION
# ==========================================
def generate_smart_meter_data(num_users=100, days=30, anomaly_rate=0.05):
    """
    Generates synthetic hourly water consumption data.
    - Simulates diurnal patterns (morning/evening peaks).
    - Injects anomalies (leaks) and different user profiles.
    """
    date_range = pd.date_range(start='2024-01-01', periods=days*24, freq='H')

    # FIXED: initialize list
    data = []

    print(f"Generating data for {num_users} users over {days} days...")

    for user_id in range(num_users):
        time_steps = np.arange(len(date_range))

        # Morning peak (8 AM)
        morning_peak = 10 * np.exp(-((time_steps % 24 - 8)**2) / 4)

        # Evening peak (7 PM)
        evening_peak = 15 * np.exp(-((time_steps % 24 - 19)**2) / 6)

        noise = np.random.normal(0, 2, len(date_range))
        usage_scale = np.random.uniform(0.5, 2.0)

        consumption = usage_scale * (morning_peak + evening_peak + 5) + noise
        consumption = np.maximum(consumption, 0)

        # Inject a leak anomaly
        if np.random.rand() < anomaly_rate:
            leak_start = np.random.randint(0, len(consumption) - 100)
            leak_duration = np.random.randint(24, 72)
            leak_volume = np.random.uniform(10, 30)

            consumption[leak_start: leak_start + leak_duration] += leak_volume
            print(f"  -> Injected leak for User_{user_id} at index {leak_start}")

        user_df = pd.DataFrame({
            'timestamp': date_range,
            'user_id': f'user_{user_id}',
            'consumption': consumption
        })
        data.append(user_df)

    return pd.concat(data).reset_index(drop=True)


# ==========================================
# 2. FEATURE ENGINEERING & K-MEANS CLUSTERING
# ==========================================
def perform_consumer_segmentation(df):

    print("\n--- Starting Consumer Segmentation ---")

    df['hour'] = df['timestamp'].dt.hour

    features = df.groupby('user_id').agg(
        mean_consumption=('consumption', 'mean'),
        std_dev=('consumption', 'std')
    )

    mnf_data = df[(df['hour'] >= 2) & (df['hour'] <= 4)].groupby('user_id')['consumption'].mean()
    features['mnf'] = mnf_data.fillna(0)

    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)

    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    features['cluster'] = kmeans.fit_predict(scaled_features)

    print("\nCluster Centers:\n", kmeans.cluster_centers_)
    print("\nCluster Counts:\n", features['cluster'].value_counts())

    return features, kmeans


# ==========================================
# 3. LSTM AUTOENCODER FOR ANOMALY DETECTION
# ==========================================
def build_lstm_autoencoder(sequence_length, n_features):
    model = Sequential()

    model.add(Input(shape=(sequence_length, n_features)))
    model.add(LSTM(64, activation='relu', return_sequences=False))
    model.add(RepeatVector(sequence_length))

    model.add(LSTM(64, activation='relu', return_sequences=True))
    model.add(TimeDistributed(Dense(n_features)))

    model.compile(optimizer='adam', loss='mse')
    return model


def detect_anomalies(df, user_id, sequence_length=24):

    print(f"\n--- Anomaly Detection for {user_id} ---")

    user_data = df[df['user_id'] == user_id]['consumption'].values.reshape(-1, 1)

    scaler = MinMaxScaler()
    user_data_scaled = scaler.fit_transform(user_data)

    # FIXED: initialize sliding window list
    X = []
    for i in range(len(user_data_scaled) - sequence_length):
        X.append(user_data_scaled[i:i+sequence_length])
    X = np.array(X)

    train_size = int(len(X) * 0.6)
    X_train, X_test = X[:train_size], X[train_size:]

    model = build_lstm_autoencoder(sequence_length, 1)
    early_stop = EarlyStopping(monitor='val_loss', patience=3, mode='min')

    print("Training LSTM Autoencoder...")
    history = model.fit(
        X_train, X_train,
        epochs=20,
        batch_size=32,
        validation_split=0.1,
        callbacks=[early_stop],
        verbose=0
    )

    X_test_pred = model.predict(X_test, verbose=0)
    test_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=(1,2))

    X_train_pred = model.predict(X_train, verbose=0)
    train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=(1,2))

    threshold = np.mean(train_mae_loss) + 4*np.std(train_mae_loss)
    print(f"Anomaly Threshold: {threshold:.4f}")

    anomalies = test_mae_loss > threshold
    print(f"Detected anomalies: {np.sum(anomalies)}")

    return test_mae_loss, threshold, anomalies, history


# ==========================================
# MAIN EXECUTION
# ==========================================
if __name__ == "__main__":

    df = generate_smart_meter_data(num_users=50, days=60, anomaly_rate=0.1)

    features_df, kmeans_model = perform_consumer_segmentation(df)

    plt.figure(figsize=(8,5))
    sns.scatterplot(
        data=features_df,
        x='mean_consumption',
        y='mnf',
        hue='cluster',
        palette='viridis'
    )
    plt.title("Consumer Segmentation")
    plt.show()

    leak_candidate = features_df['mnf'].idxmax()
    print("\nUser with highest MNF (possible leak):", leak_candidate)

    loss, thresh, anomalies, history = detect_anomalies(df, leak_candidate)

    plt.figure(figsize=(12,6))
    plt.plot(loss, label="Reconstruction Error")
    plt.axhline(y=thresh, linestyle='--', color='red', label="Threshold")
    anomaly_idx = np.where(anomalies)[0]
    plt.scatter(anomaly_idx, loss[anomaly_idx], color='red')
    plt.title(f"Anomaly Detection Results - {leak_candidate}")
    plt.legend()
    plt.show()
